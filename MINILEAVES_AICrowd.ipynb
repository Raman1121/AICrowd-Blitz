{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MINILEAVES-AICrowd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-g9JUFs7njh",
        "colab_type": "code",
        "outputId": "dff16f6a-7f0b-4462-8f7f-c97e5fb10336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from PIL import Image\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D, Dropout, MaxPooling2D, Flatten, BatchNormalization, Activation, ReLU, Input\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from learningratefinder import LearningRateFinder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "from random import seed, shuffle\n",
        "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral)\n",
        "import cv2\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LqKb8Bf8Ccm",
        "colab_type": "code",
        "outputId": "896cab10-b36e-45dc-9682-1bc7e5bf5fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        }
      },
      "source": [
        "#Donwload the datasets\n",
        "!wget https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/minileaves/v0.1/train-images.npy\n",
        "!wget https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/minileaves/v0.1/train-labels.npy\n",
        "!wget https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/minileaves/v0.1/test-images.npy\n",
        "!wget https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/minileaves/v0.1/all_classes.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-14 17:59:22--  https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/minileaves/v0.1/train-images.npy\n",
            "Resolving s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)... 130.117.252.12, 130.117.252.11, 130.117.252.16, ...\n",
            "Connecting to s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)|130.117.252.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 133527680 (127M) [binary/octet-stream]\n",
            "Saving to: ‘train-images.npy’\n",
            "\n",
            "train-images.npy    100%[===================>] 127.34M  27.8MB/s    in 8.3s    \n",
            "\n",
            "2020-05-14 17:59:31 (15.4 MB/s) - ‘train-images.npy’ saved [133527680/133527680]\n",
            "\n",
            "--2020-05-14 17:59:35--  https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/minileaves/v0.1/train-labels.npy\n",
            "Resolving s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)... 130.117.252.13, 130.117.252.10, 130.117.252.16, ...\n",
            "Connecting to s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)|130.117.252.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347856 (340K) [binary/octet-stream]\n",
            "Saving to: ‘train-labels.npy’\n",
            "\n",
            "train-labels.npy    100%[===================>] 339.70K   897KB/s    in 0.4s    \n",
            "\n",
            "2020-05-14 17:59:36 (897 KB/s) - ‘train-labels.npy’ saved [347856/347856]\n",
            "\n",
            "--2020-05-14 17:59:39--  https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/minileaves/v0.1/test-images.npy\n",
            "Resolving s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)... 130.117.252.10, 130.117.252.11, 130.117.252.12, ...\n",
            "Connecting to s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)|130.117.252.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33294464 (32M) [binary/octet-stream]\n",
            "Saving to: ‘test-images.npy’\n",
            "\n",
            "test-images.npy     100%[===================>]  31.75M  17.3MB/s    in 1.8s    \n",
            "\n",
            "2020-05-14 17:59:41 (17.3 MB/s) - ‘test-images.npy’ saved [33294464/33294464]\n",
            "\n",
            "--2020-05-14 17:59:43--  https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/minileaves/v0.1/all_classes.txt\n",
            "Resolving s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)... 130.117.252.11, 130.117.252.10, 130.117.252.12, ...\n",
            "Connecting to s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)|130.117.252.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 886 [text/plain]\n",
            "Saving to: ‘all_classes.txt’\n",
            "\n",
            "all_classes.txt     100%[===================>]     886  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-14 17:59:44 (13.8 MB/s) - ‘all_classes.txt’ saved [886/886]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYVKLkl1I3vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_encoded_labels(class_count_dict):\n",
        "  le = LabelEncoder()\n",
        "  encoded_labels = le.fit_transform(list(class_count_dict.keys()))\n",
        "  return encoded_labels\n",
        "\n",
        "def plot_acc(history):\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('Train vs Validation Accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "def plot_loss(history):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Train vs Validation Loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJGix3wU8IbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images_path = \"train-images.npy\" #path where data is stored\n",
        "train_labels_path = \"train-labels.npy\"\n",
        "test_images_path = \"test-images.npy\"\n",
        "\n",
        "train_images = np.load(train_images_path)\n",
        "train_labels = np.load(train_labels_path)\n",
        "\n",
        "test_images = np.load(test_images_path)\n",
        "\n",
        "# Load Class mapping\n",
        "class_names = [x.strip() for x in open(\"all_classes.txt\").readlines()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAk7mPmVhHOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=1.0, threshold=0):\n",
        "    \"\"\"Return a sharpened version of the image, using an unsharp mask.\"\"\"\n",
        "    blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n",
        "    sharpened = float(amount + 1) * image - float(amount) * blurred\n",
        "    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))\n",
        "    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))\n",
        "    sharpened = sharpened.round().astype(np.uint8)\n",
        "    if threshold > 0:\n",
        "        low_contrast_mask = np.absolute(image - blurred) < threshold\n",
        "        np.copyto(sharpened, image, where=low_contrast_mask)\n",
        "    return sharpened"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5_z6Wh3hMbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sharp_resized_array = []\n",
        "for i in range(len(train_images)):\n",
        "  img = train_images[i]\n",
        "  resized = cv2.resize(img, (100, 100))\n",
        "  sharp = unsharp_mask(resized)\n",
        "  sharp_resized_array.append(np.array(sharp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0b8iqvJhj8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sharp_resized_np = np.array(sharp_resized_array)\n",
        "sharp_resized_np = sharp_resized_np.astype('float32')\n",
        "sharp_resized_np = preprocess_input(sharp_resized_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LReo4D5jhuMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_cat = to_categorical(train_labels, 38)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZouBaUXhMVP",
        "colab_type": "code",
        "outputId": "5f1ef2d9-faef-4c2c-d6f7-99d5df01218c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Creating Validation Dataset\n",
        "x_train, x_val, y_train, y_val = train_test_split(sharp_resized_np, train_labels_cat, test_size = 0.2, random_state = 42)\n",
        "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.1, random_state = 42)\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34772, 100, 100, 3) (34772, 38) (8694, 100, 100, 3) (8694, 38)\n",
            "(31294, 100, 100, 3) (31294, 38) (3478, 100, 100, 3) (3478, 38)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whFB8lLaXnyA",
        "colab_type": "text"
      },
      "source": [
        "## EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3-EP9AAXnaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install efficientnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43btgxejiXa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from efficientnet.tfkeras import EfficientNetB3, EfficientNetB7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfl8ZUXLXp6x",
        "colab_type": "code",
        "outputId": "6659f762-787f-48e2-c8c7-56d65647b63c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "base_model = EfficientNetB7(weights = 'imagenet', include_top = False,\n",
        "                       input_tensor = Input(shape = (100, 100, 3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "258441216/258434480 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7LtH4dWdNUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B7TSTB4Xp3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set_trainable = False\n",
        "for layer in base_model.layers:\n",
        "  if layer.name == 'block7d_expand_conv':\n",
        "    set_trainable = True\n",
        "  if(set_trainable):\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False  \n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "preds = Dense(38, activation = 'softmax', kernel_regularizer=regularizers.l2(0.01), \n",
        "                  activity_regularizer=regularizers.l2(0.01))(x)\n",
        "\n",
        "model = Model(inputs = base_model.inputs, outputs = preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O3Hu4MsXpxW",
        "colab_type": "code",
        "outputId": "cea6e7f7-6853-4c71-b2ba-9b9c4043e606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "checkpoints_path = 'EffNet.h5'\n",
        "mc = ModelCheckpoint(filepath = checkpoints_path, monitor='val_loss', verbose=1, \n",
        "                     save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                              patience=7, min_lr=1e-5, verbose = 1)\n",
        "\n",
        "opt = Adam(lr = 1e-3, decay=1e-3/50)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7y7UcbdZNsU",
        "colab_type": "code",
        "outputId": "e8f702d4-e484-40c8-93e3-c51c5412ca16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "\t\trotation_range=20,\n",
        "\t\tzoom_range=0.15,\n",
        "\t\twidth_shift_range=0.2,\n",
        "\t\theight_shift_range=0.2,\n",
        "\t\tshear_range=0.15,\n",
        "\t\thorizontal_flip=True,\n",
        "\t\tfill_mode=\"nearest\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((31294, 100, 100, 3),\n",
              " (31294, 38),\n",
              " (8694, 100, 100, 3),\n",
              " (8694, 38),\n",
              " (3478, 100, 100, 3),\n",
              " (3478, 38))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbhT9rvAdwIx",
        "colab_type": "code",
        "outputId": "ef55e1e2-f2fe-411c-9886-6d3d372c081e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "lrf = LearningRateFinder(model)\n",
        "lrf.find(trainData=aug.flow(x_train, y_train, batch_size=128),\n",
        "startLR=1e-10, endLR=1e+1,\n",
        "stepsPerEpoch=np.ceil((len(x_train) / 128)),\n",
        "batchSize=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "245/245 [==============================] - 83s 339ms/step - loss: 4.4737 - accuracy: 0.0213\n",
            "Epoch 2/9\n",
            "245/245 [==============================] - 83s 338ms/step - loss: 4.4727 - accuracy: 0.0213\n",
            "Epoch 3/9\n",
            "245/245 [==============================] - 83s 337ms/step - loss: 4.4698 - accuracy: 0.0219\n",
            "Epoch 4/9\n",
            "245/245 [==============================] - 83s 338ms/step - loss: 4.4318 - accuracy: 0.0303\n",
            "Epoch 5/9\n",
            "245/245 [==============================] - 83s 339ms/step - loss: 3.9535 - accuracy: 0.2034\n",
            "Epoch 6/9\n",
            "245/245 [==============================] - 84s 341ms/step - loss: 2.3241 - accuracy: 0.5105\n",
            "Epoch 7/9\n",
            "245/245 [==============================] - 83s 341ms/step - loss: 2.1375 - accuracy: 0.5546\n",
            "Epoch 8/9\n",
            "245/245 [==============================] - 82s 336ms/step - loss: 11.8683 - accuracy: 0.3016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2DnDpQxd-V_",
        "colab_type": "code",
        "outputId": "96004287-897d-4f91-8956-061bddf4e649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "lrf.plot_loss()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDErOkjChjz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = EfficientNetB7(weights = 'imagenet', include_top = False,\n",
        "                       input_tensor = Input(shape = (100, 100, 3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRUkOkuGhmLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set_trainable = False\n",
        "for layer in base_model.layers:\n",
        "  if layer.name == 'block7d_expand_conv':\n",
        "    set_trainable = True\n",
        "  if(set_trainable):\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False  \n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "preds = Dense(38, activation = 'softmax', kernel_regularizer=regularizers.l2(0.01), \n",
        "                  activity_regularizer=regularizers.l2(0.01))(x)\n",
        "\n",
        "model = Model(inputs = base_model.inputs, outputs = preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT6VpWkXhtU-",
        "colab_type": "code",
        "outputId": "330aaf63-d93f-430b-8ede-779ad9ccdbd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "checkpoints_path = 'EffNet.h5'\n",
        "mc = ModelCheckpoint(filepath = checkpoints_path, monitor='val_loss', verbose=1, \n",
        "                     save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                              patience=7, min_lr=1e-5, verbose = 1)\n",
        "\n",
        "opt = Adam(lr = 1e-3, decay=1e-3/50)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iZa3GZaZNpR",
        "colab_type": "code",
        "outputId": "52e5d78e-90d4-40ab-8af4-4ba0f14a7668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(aug.flow(x_train, y_train,batch_size=128),\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          steps_per_epoch = np.ceil((len(x_train)/ float(128))),\n",
        "          validation_data=(x_val, y_val), callbacks = [mc, reduce_lr])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9954 - accuracy: 0.5498\n",
            "Epoch 00001: val_loss improved from inf to 1.21744, saving model to EffNet.h5\n",
            "245/245 [==============================] - 112s 457ms/step - loss: 1.9954 - accuracy: 0.5498 - val_loss: 1.2174 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.2943 - accuracy: 0.6870\n",
            "Epoch 00002: val_loss improved from 1.21744 to 0.95509, saving model to EffNet.h5\n",
            "245/245 [==============================] - 106s 434ms/step - loss: 1.2943 - accuracy: 0.6870 - val_loss: 0.9551 - val_accuracy: 0.7836 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1724 - accuracy: 0.7156\n",
            "Epoch 00003: val_loss improved from 0.95509 to 0.92725, saving model to EffNet.h5\n",
            "245/245 [==============================] - 107s 435ms/step - loss: 1.1724 - accuracy: 0.7156 - val_loss: 0.9272 - val_accuracy: 0.7671 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0896 - accuracy: 0.7339\n",
            "Epoch 00004: val_loss improved from 0.92725 to 0.81320, saving model to EffNet.h5\n",
            "245/245 [==============================] - 107s 435ms/step - loss: 1.0896 - accuracy: 0.7339 - val_loss: 0.8132 - val_accuracy: 0.8089 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0419 - accuracy: 0.7438\n",
            "Epoch 00005: val_loss improved from 0.81320 to 0.74421, saving model to EffNet.h5\n",
            "245/245 [==============================] - 106s 432ms/step - loss: 1.0419 - accuracy: 0.7438 - val_loss: 0.7442 - val_accuracy: 0.8427 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0068 - accuracy: 0.7523\n",
            "Epoch 00006: val_loss did not improve from 0.74421\n",
            "245/245 [==============================] - 104s 423ms/step - loss: 1.0068 - accuracy: 0.7523 - val_loss: 0.7452 - val_accuracy: 0.8233 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.9854 - accuracy: 0.7562\n",
            "Epoch 00007: val_loss improved from 0.74421 to 0.70372, saving model to EffNet.h5\n",
            "245/245 [==============================] - 106s 432ms/step - loss: 0.9854 - accuracy: 0.7562 - val_loss: 0.7037 - val_accuracy: 0.8435 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.9534 - accuracy: 0.7640\n",
            "Epoch 00008: val_loss improved from 0.70372 to 0.70069, saving model to EffNet.h5\n",
            "245/245 [==============================] - 104s 426ms/step - loss: 0.9534 - accuracy: 0.7640 - val_loss: 0.7007 - val_accuracy: 0.8359 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.9356 - accuracy: 0.7694\n",
            "Epoch 00009: val_loss improved from 0.70069 to 0.66979, saving model to EffNet.h5\n",
            "245/245 [==============================] - 105s 430ms/step - loss: 0.9356 - accuracy: 0.7694 - val_loss: 0.6698 - val_accuracy: 0.8507 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.9238 - accuracy: 0.7739\n",
            "Epoch 00010: val_loss improved from 0.66979 to 0.63501, saving model to EffNet.h5\n",
            "245/245 [==============================] - 105s 427ms/step - loss: 0.9238 - accuracy: 0.7739 - val_loss: 0.6350 - val_accuracy: 0.8558 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.9023 - accuracy: 0.7764\n",
            "Epoch 00011: val_loss improved from 0.63501 to 0.63419, saving model to EffNet.h5\n",
            "245/245 [==============================] - 105s 429ms/step - loss: 0.9023 - accuracy: 0.7764 - val_loss: 0.6342 - val_accuracy: 0.8570 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8884 - accuracy: 0.7818\n",
            "Epoch 00012: val_loss improved from 0.63419 to 0.62932, saving model to EffNet.h5\n",
            "245/245 [==============================] - 105s 428ms/step - loss: 0.8884 - accuracy: 0.7818 - val_loss: 0.6293 - val_accuracy: 0.8625 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8797 - accuracy: 0.7810\n",
            "Epoch 00013: val_loss did not improve from 0.62932\n",
            "245/245 [==============================] - 103s 421ms/step - loss: 0.8797 - accuracy: 0.7810 - val_loss: 0.6314 - val_accuracy: 0.8561 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8741 - accuracy: 0.7840\n",
            "Epoch 00014: val_loss improved from 0.62932 to 0.61402, saving model to EffNet.h5\n",
            "245/245 [==============================] - 105s 428ms/step - loss: 0.8741 - accuracy: 0.7840 - val_loss: 0.6140 - val_accuracy: 0.8611 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8611 - accuracy: 0.7861\n",
            "Epoch 00015: val_loss did not improve from 0.61402\n",
            "245/245 [==============================] - 103s 422ms/step - loss: 0.8611 - accuracy: 0.7861 - val_loss: 0.6416 - val_accuracy: 0.8515 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8634 - accuracy: 0.7870\n",
            "Epoch 00016: val_loss improved from 0.61402 to 0.61345, saving model to EffNet.h5\n",
            "245/245 [==============================] - 105s 427ms/step - loss: 0.8634 - accuracy: 0.7870 - val_loss: 0.6134 - val_accuracy: 0.8622 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8426 - accuracy: 0.7931\n",
            "Epoch 00017: val_loss did not improve from 0.61345\n",
            "245/245 [==============================] - 102s 415ms/step - loss: 0.8426 - accuracy: 0.7931 - val_loss: 0.6166 - val_accuracy: 0.8568 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8443 - accuracy: 0.7915\n",
            "Epoch 00018: val_loss improved from 0.61345 to 0.60401, saving model to EffNet.h5\n",
            "245/245 [==============================] - 104s 425ms/step - loss: 0.8443 - accuracy: 0.7915 - val_loss: 0.6040 - val_accuracy: 0.8645 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8353 - accuracy: 0.7925\n",
            "Epoch 00019: val_loss improved from 0.60401 to 0.58282, saving model to EffNet.h5\n",
            "245/245 [==============================] - 104s 426ms/step - loss: 0.8353 - accuracy: 0.7925 - val_loss: 0.5828 - val_accuracy: 0.8729 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8230 - accuracy: 0.7966\n",
            "Epoch 00020: val_loss improved from 0.58282 to 0.57037, saving model to EffNet.h5\n",
            "245/245 [==============================] - 104s 423ms/step - loss: 0.8230 - accuracy: 0.7966 - val_loss: 0.5704 - val_accuracy: 0.8757 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8170 - accuracy: 0.7983\n",
            "Epoch 00021: val_loss did not improve from 0.57037\n",
            "245/245 [==============================] - 102s 417ms/step - loss: 0.8170 - accuracy: 0.7983 - val_loss: 0.5708 - val_accuracy: 0.8741 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8169 - accuracy: 0.7971\n",
            "Epoch 00022: val_loss improved from 0.57037 to 0.54736, saving model to EffNet.h5\n",
            "245/245 [==============================] - 107s 437ms/step - loss: 0.8169 - accuracy: 0.7971 - val_loss: 0.5474 - val_accuracy: 0.8790 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7967 - accuracy: 0.8033\n",
            "Epoch 00023: val_loss did not improve from 0.54736\n",
            "245/245 [==============================] - 104s 424ms/step - loss: 0.7967 - accuracy: 0.8033 - val_loss: 0.6134 - val_accuracy: 0.8536 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7994 - accuracy: 0.7992\n",
            "Epoch 00024: val_loss did not improve from 0.54736\n",
            "245/245 [==============================] - 104s 424ms/step - loss: 0.7994 - accuracy: 0.7992 - val_loss: 0.5489 - val_accuracy: 0.8772 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7940 - accuracy: 0.8043\n",
            "Epoch 00025: val_loss improved from 0.54736 to 0.54249, saving model to EffNet.h5\n",
            "245/245 [==============================] - 105s 430ms/step - loss: 0.7940 - accuracy: 0.8043 - val_loss: 0.5425 - val_accuracy: 0.8792 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7879 - accuracy: 0.8051\n",
            "Epoch 00026: val_loss improved from 0.54249 to 0.53534, saving model to EffNet.h5\n",
            "245/245 [==============================] - 104s 426ms/step - loss: 0.7879 - accuracy: 0.8051 - val_loss: 0.5353 - val_accuracy: 0.8843 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7806 - accuracy: 0.8076\n",
            "Epoch 00027: val_loss improved from 0.53534 to 0.53351, saving model to EffNet.h5\n",
            "245/245 [==============================] - 105s 428ms/step - loss: 0.7806 - accuracy: 0.8076 - val_loss: 0.5335 - val_accuracy: 0.8870 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7915 - accuracy: 0.8039\n",
            "Epoch 00028: val_loss did not improve from 0.53351\n",
            "245/245 [==============================] - 103s 420ms/step - loss: 0.7915 - accuracy: 0.8039 - val_loss: 0.5642 - val_accuracy: 0.8699 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7746 - accuracy: 0.8085\n",
            "Epoch 00029: val_loss did not improve from 0.53351\n",
            "245/245 [==============================] - 102s 417ms/step - loss: 0.7746 - accuracy: 0.8085 - val_loss: 0.5411 - val_accuracy: 0.8820 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7736 - accuracy: 0.8091\n",
            "Epoch 00030: val_loss did not improve from 0.53351\n",
            "245/245 [==============================] - 102s 417ms/step - loss: 0.7736 - accuracy: 0.8091 - val_loss: 0.5542 - val_accuracy: 0.8734 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7714 - accuracy: 0.8090\n",
            "Epoch 00031: val_loss did not improve from 0.53351\n",
            "245/245 [==============================] - 103s 419ms/step - loss: 0.7714 - accuracy: 0.8090 - val_loss: 0.5390 - val_accuracy: 0.8798 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7645 - accuracy: 0.8115\n",
            "Epoch 00032: val_loss did not improve from 0.53351\n",
            "245/245 [==============================] - 103s 422ms/step - loss: 0.7645 - accuracy: 0.8115 - val_loss: 0.5621 - val_accuracy: 0.8658 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7532 - accuracy: 0.8158\n",
            "Epoch 00033: val_loss improved from 0.53351 to 0.52165, saving model to EffNet.h5\n",
            "245/245 [==============================] - 105s 427ms/step - loss: 0.7532 - accuracy: 0.8158 - val_loss: 0.5216 - val_accuracy: 0.8847 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7489 - accuracy: 0.8135\n",
            "Epoch 00034: val_loss did not improve from 0.52165\n",
            "245/245 [==============================] - 103s 421ms/step - loss: 0.7489 - accuracy: 0.8135 - val_loss: 0.5552 - val_accuracy: 0.8736 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7518 - accuracy: 0.8154\n",
            "Epoch 00035: val_loss did not improve from 0.52165\n",
            "245/245 [==============================] - 103s 422ms/step - loss: 0.7518 - accuracy: 0.8154 - val_loss: 0.5302 - val_accuracy: 0.8834 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7464 - accuracy: 0.8143\n",
            "Epoch 00036: val_loss improved from 0.52165 to 0.51961, saving model to EffNet.h5\n",
            "245/245 [==============================] - 104s 424ms/step - loss: 0.7464 - accuracy: 0.8143 - val_loss: 0.5196 - val_accuracy: 0.8821 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7472 - accuracy: 0.8174\n",
            "Epoch 00037: val_loss did not improve from 0.51961\n",
            "245/245 [==============================] - 102s 416ms/step - loss: 0.7472 - accuracy: 0.8174 - val_loss: 0.5328 - val_accuracy: 0.8758 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7362 - accuracy: 0.8181\n",
            "Epoch 00038: val_loss did not improve from 0.51961\n",
            "245/245 [==============================] - 102s 415ms/step - loss: 0.7362 - accuracy: 0.8181 - val_loss: 0.5319 - val_accuracy: 0.8784 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7405 - accuracy: 0.8176\n",
            "Epoch 00039: val_loss improved from 0.51961 to 0.51806, saving model to EffNet.h5\n",
            "245/245 [==============================] - 104s 426ms/step - loss: 0.7405 - accuracy: 0.8176 - val_loss: 0.5181 - val_accuracy: 0.8857 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7450 - accuracy: 0.8172\n",
            "Epoch 00040: val_loss improved from 0.51806 to 0.49050, saving model to EffNet.h5\n",
            "245/245 [==============================] - 108s 441ms/step - loss: 0.7450 - accuracy: 0.8172 - val_loss: 0.4905 - val_accuracy: 0.8974 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7325 - accuracy: 0.8196\n",
            "Epoch 00041: val_loss did not improve from 0.49050\n",
            "245/245 [==============================] - 106s 433ms/step - loss: 0.7325 - accuracy: 0.8196 - val_loss: 0.5420 - val_accuracy: 0.8815 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.8181\n",
            "Epoch 00042: val_loss did not improve from 0.49050\n",
            "245/245 [==============================] - 106s 433ms/step - loss: 0.7448 - accuracy: 0.8181 - val_loss: 0.5048 - val_accuracy: 0.8884 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7299 - accuracy: 0.8189\n",
            "Epoch 00043: val_loss improved from 0.49050 to 0.48965, saving model to EffNet.h5\n",
            "245/245 [==============================] - 109s 444ms/step - loss: 0.7299 - accuracy: 0.8189 - val_loss: 0.4896 - val_accuracy: 0.8971 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.8213\n",
            "Epoch 00044: val_loss improved from 0.48965 to 0.47337, saving model to EffNet.h5\n",
            "245/245 [==============================] - 108s 441ms/step - loss: 0.7279 - accuracy: 0.8213 - val_loss: 0.4734 - val_accuracy: 0.8980 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7236 - accuracy: 0.8207\n",
            "Epoch 00045: val_loss did not improve from 0.47337\n",
            "245/245 [==============================] - 106s 432ms/step - loss: 0.7236 - accuracy: 0.8207 - val_loss: 0.4895 - val_accuracy: 0.8918 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7252 - accuracy: 0.8219\n",
            "Epoch 00046: val_loss did not improve from 0.47337\n",
            "245/245 [==============================] - 106s 431ms/step - loss: 0.7252 - accuracy: 0.8219 - val_loss: 0.4838 - val_accuracy: 0.8969 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7181 - accuracy: 0.8220\n",
            "Epoch 00047: val_loss improved from 0.47337 to 0.46525, saving model to EffNet.h5\n",
            "245/245 [==============================] - 108s 441ms/step - loss: 0.7181 - accuracy: 0.8220 - val_loss: 0.4652 - val_accuracy: 0.8999 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7213 - accuracy: 0.8219\n",
            "Epoch 00048: val_loss did not improve from 0.46525\n",
            "245/245 [==============================] - 106s 432ms/step - loss: 0.7213 - accuracy: 0.8219 - val_loss: 0.5304 - val_accuracy: 0.8781 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7097 - accuracy: 0.8267\n",
            "Epoch 00049: val_loss did not improve from 0.46525\n",
            "245/245 [==============================] - 106s 434ms/step - loss: 0.7097 - accuracy: 0.8267 - val_loss: 0.4989 - val_accuracy: 0.8883 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7162 - accuracy: 0.8221\n",
            "Epoch 00050: val_loss did not improve from 0.46525\n",
            "245/245 [==============================] - 106s 434ms/step - loss: 0.7162 - accuracy: 0.8221 - val_loss: 0.5039 - val_accuracy: 0.8903 - lr: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zvZffxP39Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LOAD THE EFFNET MODEL HERE AND FINE TUNE IT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXOXI6OTZNlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in base_model.layers:\n",
        "  layer.trainable = True\n",
        "\n",
        "opt = Adam(lr = 1e-5, decay=1e-5/50)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeGF7G47ZNgY",
        "colab_type": "code",
        "outputId": "19ca4416-d51e-49be-8c99-77535c5e337f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "history = model.fit_generator(aug.flow(x_train, y_train,batch_size=128),\n",
        "          epochs=30,\n",
        "          verbose=1,\n",
        "          steps_per_epoch = np.ceil((len(x_train)/ float(128))),\n",
        "          validation_data=(x_val, y_val), callbacks = [mc, reduce_lr])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ef7c828b962b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           validation_data=(x_val, y_val), callbacks = [mc, reduce_lr])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,1344,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_2/block5e_expand_conv/Conv2D (defined at <ipython-input-30-ef7c828b962b>:5) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_340335]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUjyneadn39v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_LR(model, batch_size, x_train, y_train, aug, class_weight=None):\n",
        "  lrf = LearningRateFinder(model)\n",
        "  lrf.find(aug.flow(x_train, y_train, batch_size=batch_size),\n",
        "    1e-10, 1e+1,\n",
        "    stepsPerEpoch=np.ceil((len(x_train) / batch_size)),\n",
        "    batchSize=batch_size)\n",
        " \n",
        "  lrf.plot_loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU6ofAHeTUnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining the model\n",
        "def get_model(shape=(224, 224, 3), weights = None):\n",
        "    base_model = DenseNet121(include_top = False, weights = weights, \n",
        "                             input_tensor=Input(shape=shape))\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    #x = Dense(512, activation = 'relu')(x)\n",
        "    preds = Dense(38, activation = 'softmax', kernel_regularizer=regularizers.l2(0.01), \n",
        "                  activity_regularizer=regularizers.l2(0.01))(x)\n",
        "\n",
        "    model = Model(inputs = base_model.inputs, outputs = preds)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4flZoNqj8sFi",
        "colab_type": "code",
        "outputId": "adad6eaf-5b53-44f0-f971-35152617c988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "data_counter = Counter(train_labels)\n",
        "unique_class_indices = data_counter.keys()\n",
        "class_count_dict = {}\n",
        "\n",
        "for _class_index in unique_class_indices:\n",
        "    print(\"Class Index : \", _class_index)\n",
        "    print(\"Class Name : \", class_names[_class_index])\n",
        "    print(\"Number of images in the dataset : \", data_counter[_class_index])\n",
        "    class_count_dict[_class_index] = data_counter[_class_index]\n",
        "    print(\"=\"*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class Index :  7\n",
            "Class Name :  corn-maize-cercospora-leaf-spot-gray-leaf-spot\n",
            "Number of images in the dataset :  410\n",
            "====================================================================================================\n",
            "Class Index :  4\n",
            "Class Name :  blueberry-healthy\n",
            "Number of images in the dataset :  1205\n",
            "====================================================================================================\n",
            "Class Index :  9\n",
            "Class Name :  corn-maize-healthy\n",
            "Number of images in the dataset :  925\n",
            "====================================================================================================\n",
            "Class Index :  29\n",
            "Class Name :  tomato-early-blight\n",
            "Number of images in the dataset :  806\n",
            "====================================================================================================\n",
            "Class Index :  20\n",
            "Class Name :  potato-early-blight\n",
            "Number of images in the dataset :  808\n",
            "====================================================================================================\n",
            "Class Index :  15\n",
            "Class Name :  orange-haunglongbing-citrus-greening\n",
            "Number of images in the dataset :  4422\n",
            "====================================================================================================\n",
            "Class Index :  37\n",
            "Class Name :  tomato-tomato-yellow-leaf-curl-virus\n",
            "Number of images in the dataset :  4238\n",
            "====================================================================================================\n",
            "Class Index :  5\n",
            "Class Name :  cherry-including-sour-healthy\n",
            "Number of images in the dataset :  666\n",
            "====================================================================================================\n",
            "Class Index :  28\n",
            "Class Name :  tomato-bacterial-spot\n",
            "Number of images in the dataset :  1738\n",
            "====================================================================================================\n",
            "Class Index :  16\n",
            "Class Name :  peach-bacterial-spot\n",
            "Number of images in the dataset :  1864\n",
            "====================================================================================================\n",
            "Class Index :  14\n",
            "Class Name :  grape-leaf-blight-isariopsis-leaf-spot\n",
            "Number of images in the dataset :  865\n",
            "====================================================================================================\n",
            "Class Index :  12\n",
            "Class Name :  grape-esca-black-measles\n",
            "Number of images in the dataset :  1090\n",
            "====================================================================================================\n",
            "Class Index :  3\n",
            "Class Name :  apple-healthy\n",
            "Number of images in the dataset :  1313\n",
            "====================================================================================================\n",
            "Class Index :  10\n",
            "Class Name :  corn-maize-northern-leaf-blight\n",
            "Number of images in the dataset :  794\n",
            "====================================================================================================\n",
            "Class Index :  24\n",
            "Class Name :  soybean-healthy\n",
            "Number of images in the dataset :  4087\n",
            "====================================================================================================\n",
            "Class Index :  33\n",
            "Class Name :  tomato-septoria-leaf-spot\n",
            "Number of images in the dataset :  1439\n",
            "====================================================================================================\n",
            "Class Index :  25\n",
            "Class Name :  squash-powdery-mildew\n",
            "Number of images in the dataset :  1476\n",
            "====================================================================================================\n",
            "Class Index :  18\n",
            "Class Name :  pepper-bell-bacterial-spot\n",
            "Number of images in the dataset :  799\n",
            "====================================================================================================\n",
            "Class Index :  23\n",
            "Class Name :  raspberry-healthy\n",
            "Number of images in the dataset :  297\n",
            "====================================================================================================\n",
            "Class Index :  31\n",
            "Class Name :  tomato-late-blight\n",
            "Number of images in the dataset :  1522\n",
            "====================================================================================================\n",
            "Class Index :  11\n",
            "Class Name :  grape-black-rot\n",
            "Number of images in the dataset :  953\n",
            "====================================================================================================\n",
            "Class Index :  32\n",
            "Class Name :  tomato-leaf-mold\n",
            "Number of images in the dataset :  763\n",
            "====================================================================================================\n",
            "Class Index :  22\n",
            "Class Name :  potato-late-blight\n",
            "Number of images in the dataset :  789\n",
            "====================================================================================================\n",
            "Class Index :  17\n",
            "Class Name :  peach-healthy\n",
            "Number of images in the dataset :  286\n",
            "====================================================================================================\n",
            "Class Index :  35\n",
            "Class Name :  tomato-target-spot\n",
            "Number of images in the dataset :  1117\n",
            "====================================================================================================\n",
            "Class Index :  6\n",
            "Class Name :  cherry-including-sour-powdery-mildew\n",
            "Number of images in the dataset :  820\n",
            "====================================================================================================\n",
            "Class Index :  34\n",
            "Class Name :  tomato-spider-mites-two-spotted-spider-mite\n",
            "Number of images in the dataset :  1327\n",
            "====================================================================================================\n",
            "Class Index :  30\n",
            "Class Name :  tomato-healthy\n",
            "Number of images in the dataset :  1266\n",
            "====================================================================================================\n",
            "Class Index :  13\n",
            "Class Name :  grape-healthy\n",
            "Number of images in the dataset :  337\n",
            "====================================================================================================\n",
            "Class Index :  19\n",
            "Class Name :  pepper-bell-healthy\n",
            "Number of images in the dataset :  1165\n",
            "====================================================================================================\n",
            "Class Index :  27\n",
            "Class Name :  strawberry-leaf-scorch\n",
            "Number of images in the dataset :  883\n",
            "====================================================================================================\n",
            "Class Index :  0\n",
            "Class Name :  apple-apple-scab\n",
            "Number of images in the dataset :  511\n",
            "====================================================================================================\n",
            "Class Index :  1\n",
            "Class Name :  apple-black-rot\n",
            "Number of images in the dataset :  506\n",
            "====================================================================================================\n",
            "Class Index :  21\n",
            "Class Name :  potato-healthy\n",
            "Number of images in the dataset :  120\n",
            "====================================================================================================\n",
            "Class Index :  36\n",
            "Class Name :  tomato-tomato-mosaic-virus\n",
            "Number of images in the dataset :  301\n",
            "====================================================================================================\n",
            "Class Index :  8\n",
            "Class Name :  corn-maize-common-rust\n",
            "Number of images in the dataset :  960\n",
            "====================================================================================================\n",
            "Class Index :  26\n",
            "Class Name :  strawberry-healthy\n",
            "Number of images in the dataset :  376\n",
            "====================================================================================================\n",
            "Class Index :  2\n",
            "Class Name :  apple-cedar-apple-rust\n",
            "Number of images in the dataset :  222\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydYoxKpZctH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_class_weight(labels_dict,mu=0.15):\n",
        "    total = np.sum(list(labels_dict.values()))\n",
        "    keys = list(labels_dict.keys())\n",
        "    class_weight = dict()\n",
        "\n",
        "    for key in keys:\n",
        "        score = math.log(mu*total/float(labels_dict[key]))\n",
        "        class_weight[key] = score if score > 1.0 else 1.0\n",
        "\n",
        "    return class_weight\n",
        "\n",
        "class_w = create_class_weight(class_count_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnmfVn8z86Iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = sorted(class_count_dict.values())\n",
        "for k in l:\n",
        "  for key, val in class_count_dict.items():\n",
        "    if(val == k):\n",
        "      #print(key, class_count_dict[key])\n",
        "      sorted_dict[key] = class_count_dict[key]\n",
        "\n",
        "encoded_labels = get_encoded_labels(class_count_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VamfqZZkm1GB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_dict = sorted(class_count_dict.items(), key=lambda x: x[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4HZhocIut8D",
        "colab_type": "code",
        "outputId": "af2a38cc-ad9d-4165-9dcf-66ea7c49056e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "sorted_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(21, 120),\n",
              " (2, 222),\n",
              " (17, 286),\n",
              " (23, 297),\n",
              " (36, 301),\n",
              " (13, 337),\n",
              " (26, 376),\n",
              " (7, 410),\n",
              " (1, 506),\n",
              " (0, 511),\n",
              " (5, 666),\n",
              " (32, 763),\n",
              " (22, 789),\n",
              " (10, 794),\n",
              " (18, 799),\n",
              " (29, 806),\n",
              " (20, 808),\n",
              " (6, 820),\n",
              " (14, 865),\n",
              " (27, 883),\n",
              " (9, 925),\n",
              " (11, 953),\n",
              " (8, 960),\n",
              " (12, 1090),\n",
              " (35, 1117),\n",
              " (19, 1165),\n",
              " (4, 1205),\n",
              " (30, 1266),\n",
              " (3, 1313),\n",
              " (34, 1327),\n",
              " (33, 1439),\n",
              " (25, 1476),\n",
              " (31, 1522),\n",
              " (28, 1738),\n",
              " (16, 1864),\n",
              " (24, 4087),\n",
              " (37, 4238),\n",
              " (15, 4422)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DmWP-MWoTI8",
        "colab_type": "code",
        "outputId": "ebf4d955-1972-4617-de30-1f15ceaa2cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "minority_classes = []\n",
        "for key in class_count_dict.keys():\n",
        "  if(class_count_dict[key] < 900):\n",
        "    minority_classes.append(key)\n",
        "(minority_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 29, 20, 5, 14, 10, 18, 23, 32, 22, 17, 6, 13, 27, 0, 1, 21, 36, 26, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky7hCAZHppVr",
        "colab_type": "text"
      },
      "source": [
        "# Augmenting the Minority Class#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWo39tZRpsGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Minority List -> minority_classes\n",
        "# Iterate through 'minority_classes', pick that image from the train data where the label is from the minority class\n",
        "new_data=[]\n",
        "new_labels = []\n",
        "count = 0\n",
        "for i in train_labels:\n",
        "  if(i in minority_classes):\n",
        "    count+=1\n",
        "    img = train_images[i]\n",
        "    img_PIL = Image.fromarray(img)\n",
        "    img_PIL = img_PIL.convert(\"RGB\")\n",
        "    r,g,b = img_PIL.split()\n",
        "    r = r.convert(\"RGB\")\n",
        "    g = g.convert(\"RGB\")\n",
        "    b = b.convert(\"RGB\")\n",
        "    new_data.append(np.array(r))\n",
        "    new_data.append(np.array(g))\n",
        "    new_data.append(np.array(b))\n",
        "    new_labels.append(i)\n",
        "    new_labels.append(i)\n",
        "    new_labels.append(i)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hsmvO3apr_R",
        "colab_type": "code",
        "outputId": "dc3951c8-a364-4a11-c42a-6f09723ec191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.array(new_data).shape, np.array(new_labels).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((34077, 32, 32, 3), (34077,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKG8iCe5pr6d",
        "colab_type": "code",
        "outputId": "2efcf31d-cfca-4bb1-ecfb-5690d124332a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "NEW_TRAIN_IMAGES = np.append(train_images, np.array(new_data), axis = 0)\n",
        "NEW_TRAIN_LABELS = np.append(train_labels, np.array(new_labels), axis = 0)\n",
        "NEW_TRAIN_IMAGES.shape, NEW_TRAIN_LABELS.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((77543, 32, 32, 3), (77543,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N23OP0s_z6X5",
        "colab_type": "code",
        "outputId": "0860dd72-2383-44f5-e289-f386f4ededb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "FINAL_LABELS = to_categorical(NEW_TRAIN_LABELS, 38)\n",
        "FINAL_LABELS.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77543, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh1FtabBprsb",
        "colab_type": "code",
        "outputId": "38d51b09-23d2-4b8b-e48f-ffc55c4eb0c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "FINAL_DATA = []\n",
        "for i in range(len(NEW_TRAIN_IMAGES)):\n",
        "  img = NEW_TRAIN_IMAGES[i]\n",
        "  resized = cv2.resize(img, (128, 128))\n",
        "  sharp = unsharp_mask(resized)\n",
        "  FINAL_DATA.append(np.array(sharp))\n",
        "\n",
        "np.array(FINAL_DATA).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77543, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HobZXOcMx_xa",
        "colab_type": "code",
        "outputId": "554519aa-6fbb-47be-f003-99cf4567296f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Creating Validation Dataset\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(FINAL_DATA), FINAL_LABELS, test_size = 0.1, random_state = 42)\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)\n",
        "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(69788, 128, 128, 3) (69788, 38) (7755, 128, 128, 3) (7755, 38)\n",
            "(55830, 128, 128, 3) (55830, 38) (13958, 128, 128, 3) (13958, 38)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqcN5EVozC7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.astype('float32')\n",
        "x_val.astype('float32')\n",
        "x_test.astype('float32')\n",
        "\n",
        "x_train = preprocess_input(x_train)\n",
        "x_val = preprocess_input(x_val)\n",
        "x_test = preprocess_input(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rtWc3-5OqaM",
        "colab_type": "text"
      },
      "source": [
        "## Basic Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRBiUsOnr2ae",
        "colab_type": "code",
        "outputId": "faecf4f5-f9a9-4318-a286-5fb506d82bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "\t\trotation_range=20,\n",
        "\t\tzoom_range=0.15,\n",
        "\t\twidth_shift_range=0.2,\n",
        "\t\theight_shift_range=0.2,\n",
        "\t\tshear_range=0.15,\n",
        "\t\thorizontal_flip=True,\n",
        "\t\tfill_mode=\"nearest\")\n",
        "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((55830, 128, 128, 3),\n",
              " (55830, 38),\n",
              " (13958, 128, 128, 3),\n",
              " (13958, 38),\n",
              " (7755, 128, 128, 3),\n",
              " (7755, 38))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9ur_GhMsfKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_model = get_model(shape = (128, 128, 3), weights='imagenet')\n",
        "for layer in test_model.layers[:20]:\n",
        "  layer.trainable = False\n",
        "\n",
        "opt = SGD()\n",
        "test_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sUxSDSUkIcu",
        "colab_type": "code",
        "outputId": "5e067c58-686b-46e8-c0d6-ba38d646364e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "lrf = LearningRateFinder(test_model)\n",
        "lrf.find(trainData=aug.flow(x_train, y_train, batch_size=128),\n",
        "startLR=1e-10, endLR=1e+1,\n",
        "stepsPerEpoch=np.ceil((len(x_train) / 128)),\n",
        "batchSize=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/learningratefinder.py:143: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/5\n",
            "437/437 [==============================] - 361s 826ms/step - loss: 5.6484 - accuracy: 0.0215\n",
            "Epoch 2/5\n",
            "437/437 [==============================] - 358s 820ms/step - loss: 5.6376 - accuracy: 0.0210\n",
            "Epoch 3/5\n",
            "437/437 [==============================] - 358s 820ms/step - loss: 5.3961 - accuracy: 0.0325\n",
            "Epoch 4/5\n",
            "437/437 [==============================] - 358s 820ms/step - loss: 2.2274 - accuracy: 0.6279\n",
            "Epoch 5/5\n",
            "437/437 [==============================] - 357s 816ms/step - loss: 2.9510 - accuracy: 0.4486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHz2Uk26sBmz",
        "colab_type": "code",
        "outputId": "2a003544-e743-4034-8b15-6785bda0c23e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "lrf.plot_loss()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSbCFFfM0zfS",
        "colab_type": "text"
      },
      "source": [
        "## Defining the model with the optimum LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zcGvvZgnNxD",
        "colab_type": "code",
        "outputId": "cf7cb9b5-aa31-468e-e358-6271678512c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model = get_model(shape=(128,128,3), weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmF8pld1iCgV",
        "colab_type": "code",
        "outputId": "9abfc740-a1e6-4a17-d316-f7208b700e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "checkpoints_path = 'Densenet-BALANCED_DATA.h5'\n",
        "mc = ModelCheckpoint(filepath = checkpoints_path, monitor='val_loss', verbose=1, \n",
        "                     save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                              patience=10, min_lr=1e-3, verbose = 1)\n",
        "\n",
        "opt = SGD(lr = 9e-2, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_1Vhh24Pq-y",
        "colab_type": "code",
        "outputId": "c20e93d3-e2ef-4264-cf49-6565b1898dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=70,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val), callbacks = [mc, reduce_lr])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 1.8747 - accuracy: 0.6621\n",
            "Epoch 00001: val_loss improved from inf to 2.05249, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 114s 262ms/step - loss: 1.8747 - accuracy: 0.6621 - val_loss: 2.0525 - val_accuracy: 0.5088 - lr: 0.0900\n",
            "Epoch 2/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.7893 - accuracy: 0.8394\n",
            "Epoch 00002: val_loss improved from 2.05249 to 0.90978, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.7893 - accuracy: 0.8394 - val_loss: 0.9098 - val_accuracy: 0.7952 - lr: 0.0900\n",
            "Epoch 3/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.6415 - accuracy: 0.8706\n",
            "Epoch 00003: val_loss improved from 0.90978 to 0.70894, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.6415 - accuracy: 0.8706 - val_loss: 0.7089 - val_accuracy: 0.8532 - lr: 0.0900\n",
            "Epoch 4/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.8932\n",
            "Epoch 00004: val_loss improved from 0.70894 to 0.69800, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.5525 - accuracy: 0.8932 - val_loss: 0.6980 - val_accuracy: 0.8716 - lr: 0.0900\n",
            "Epoch 5/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.9107\n",
            "Epoch 00005: val_loss improved from 0.69800 to 0.69071, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.4834 - accuracy: 0.9107 - val_loss: 0.6907 - val_accuracy: 0.8389 - lr: 0.0900\n",
            "Epoch 6/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.4154 - accuracy: 0.9258\n",
            "Epoch 00006: val_loss improved from 0.69071 to 0.53292, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.4154 - accuracy: 0.9258 - val_loss: 0.5329 - val_accuracy: 0.9020 - lr: 0.0900\n",
            "Epoch 7/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.9352\n",
            "Epoch 00007: val_loss did not improve from 0.53292\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.3804 - accuracy: 0.9352 - val_loss: 0.5478 - val_accuracy: 0.8895 - lr: 0.0900\n",
            "Epoch 8/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.3508 - accuracy: 0.9420\n",
            "Epoch 00008: val_loss improved from 0.53292 to 0.40685, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.3508 - accuracy: 0.9420 - val_loss: 0.4069 - val_accuracy: 0.9257 - lr: 0.0900\n",
            "Epoch 9/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.9471\n",
            "Epoch 00009: val_loss improved from 0.40685 to 0.40499, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.3301 - accuracy: 0.9471 - val_loss: 0.4050 - val_accuracy: 0.9319 - lr: 0.0900\n",
            "Epoch 10/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.9576\n",
            "Epoch 00010: val_loss improved from 0.40499 to 0.30258, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.2766 - accuracy: 0.9576 - val_loss: 0.3026 - val_accuracy: 0.9508 - lr: 0.0900\n",
            "Epoch 11/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.9628\n",
            "Epoch 00011: val_loss improved from 0.30258 to 0.26902, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.2571 - accuracy: 0.9628 - val_loss: 0.2690 - val_accuracy: 0.9590 - lr: 0.0900\n",
            "Epoch 12/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.9641\n",
            "Epoch 00012: val_loss did not improve from 0.26902\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.2521 - accuracy: 0.9641 - val_loss: 0.3353 - val_accuracy: 0.9414 - lr: 0.0900\n",
            "Epoch 13/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9684\n",
            "Epoch 00013: val_loss did not improve from 0.26902\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.2262 - accuracy: 0.9684 - val_loss: 0.3408 - val_accuracy: 0.9375 - lr: 0.0900\n",
            "Epoch 14/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.9695\n",
            "Epoch 00014: val_loss improved from 0.26902 to 0.23127, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 113s 258ms/step - loss: 0.2282 - accuracy: 0.9695 - val_loss: 0.2313 - val_accuracy: 0.9627 - lr: 0.0900\n",
            "Epoch 15/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2052 - accuracy: 0.9730\n",
            "Epoch 00015: val_loss did not improve from 0.23127\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.2052 - accuracy: 0.9730 - val_loss: 0.2807 - val_accuracy: 0.9600 - lr: 0.0900\n",
            "Epoch 16/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.9737\n",
            "Epoch 00016: val_loss did not improve from 0.23127\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.2038 - accuracy: 0.9737 - val_loss: 0.3295 - val_accuracy: 0.9475 - lr: 0.0900\n",
            "Epoch 17/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9770\n",
            "Epoch 00017: val_loss did not improve from 0.23127\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.1864 - accuracy: 0.9770 - val_loss: 0.2574 - val_accuracy: 0.9586 - lr: 0.0900\n",
            "Epoch 18/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 0.9794\n",
            "Epoch 00018: val_loss improved from 0.23127 to 0.15494, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.1791 - accuracy: 0.9794 - val_loss: 0.1549 - val_accuracy: 0.9801 - lr: 0.0900\n",
            "Epoch 19/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9794\n",
            "Epoch 00019: val_loss did not improve from 0.15494\n",
            "437/437 [==============================] - 112s 255ms/step - loss: 0.1777 - accuracy: 0.9794 - val_loss: 0.2573 - val_accuracy: 0.9598 - lr: 0.0900\n",
            "Epoch 20/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9812\n",
            "Epoch 00020: val_loss did not improve from 0.15494\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.1628 - accuracy: 0.9812 - val_loss: 0.2224 - val_accuracy: 0.9635 - lr: 0.0900\n",
            "Epoch 21/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9847\n",
            "Epoch 00021: val_loss did not improve from 0.15494\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.1470 - accuracy: 0.9847 - val_loss: 0.1739 - val_accuracy: 0.9773 - lr: 0.0900\n",
            "Epoch 22/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.9878\n",
            "Epoch 00022: val_loss did not improve from 0.15494\n",
            "437/437 [==============================] - 112s 255ms/step - loss: 0.1285 - accuracy: 0.9878 - val_loss: 0.3126 - val_accuracy: 0.9483 - lr: 0.0900\n",
            "Epoch 23/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9889\n",
            "Epoch 00023: val_loss did not improve from 0.15494\n",
            "437/437 [==============================] - 112s 255ms/step - loss: 0.1256 - accuracy: 0.9889 - val_loss: 0.2029 - val_accuracy: 0.9680 - lr: 0.0900\n",
            "Epoch 24/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.9819\n",
            "Epoch 00024: val_loss did not improve from 0.15494\n",
            "437/437 [==============================] - 112s 255ms/step - loss: 0.1706 - accuracy: 0.9819 - val_loss: 0.2773 - val_accuracy: 0.9543 - lr: 0.0900\n",
            "Epoch 25/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.9870\n",
            "Epoch 00025: val_loss did not improve from 0.15494\n",
            "437/437 [==============================] - 112s 255ms/step - loss: 0.1389 - accuracy: 0.9870 - val_loss: 0.2116 - val_accuracy: 0.9709 - lr: 0.0900\n",
            "Epoch 26/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.9867\n",
            "Epoch 00026: val_loss did not improve from 0.15494\n",
            "437/437 [==============================] - 112s 255ms/step - loss: 0.1407 - accuracy: 0.9867 - val_loss: 0.1693 - val_accuracy: 0.9749 - lr: 0.0900\n",
            "Epoch 27/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9924\n",
            "Epoch 00027: val_loss did not improve from 0.15494\n",
            "437/437 [==============================] - 112s 255ms/step - loss: 0.0979 - accuracy: 0.9924 - val_loss: 0.1724 - val_accuracy: 0.9757 - lr: 0.0900\n",
            "Epoch 28/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9891\n",
            "Epoch 00028: val_loss did not improve from 0.15494\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.04500000178813934.\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.1223 - accuracy: 0.9891 - val_loss: 0.1631 - val_accuracy: 0.9769 - lr: 0.0900\n",
            "Epoch 29/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9958\n",
            "Epoch 00029: val_loss improved from 0.15494 to 0.08825, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 113s 258ms/step - loss: 0.0870 - accuracy: 0.9958 - val_loss: 0.0883 - val_accuracy: 0.9902 - lr: 0.0450\n",
            "Epoch 30/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9983\n",
            "Epoch 00030: val_loss did not improve from 0.08825\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0592 - accuracy: 0.9983 - val_loss: 0.0996 - val_accuracy: 0.9873 - lr: 0.0450\n",
            "Epoch 31/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9987\n",
            "Epoch 00031: val_loss improved from 0.08825 to 0.08601, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 113s 257ms/step - loss: 0.0566 - accuracy: 0.9987 - val_loss: 0.0860 - val_accuracy: 0.9908 - lr: 0.0450\n",
            "Epoch 32/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9986\n",
            "Epoch 00032: val_loss improved from 0.08601 to 0.08449, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.0563 - accuracy: 0.9986 - val_loss: 0.0845 - val_accuracy: 0.9905 - lr: 0.0450\n",
            "Epoch 33/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9990\n",
            "Epoch 00033: val_loss improved from 0.08449 to 0.08127, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.0526 - accuracy: 0.9990 - val_loss: 0.0813 - val_accuracy: 0.9908 - lr: 0.0450\n",
            "Epoch 34/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9993\n",
            "Epoch 00034: val_loss improved from 0.08127 to 0.08059, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 113s 258ms/step - loss: 0.0505 - accuracy: 0.9993 - val_loss: 0.0806 - val_accuracy: 0.9902 - lr: 0.0450\n",
            "Epoch 35/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9996\n",
            "Epoch 00035: val_loss improved from 0.08059 to 0.07901, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 113s 257ms/step - loss: 0.0487 - accuracy: 0.9996 - val_loss: 0.0790 - val_accuracy: 0.9908 - lr: 0.0450\n",
            "Epoch 36/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9995\n",
            "Epoch 00036: val_loss improved from 0.07901 to 0.07611, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.0485 - accuracy: 0.9995 - val_loss: 0.0761 - val_accuracy: 0.9909 - lr: 0.0450\n",
            "Epoch 37/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9989\n",
            "Epoch 00037: val_loss did not improve from 0.07611\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0520 - accuracy: 0.9989 - val_loss: 0.0797 - val_accuracy: 0.9906 - lr: 0.0450\n",
            "Epoch 38/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9995\n",
            "Epoch 00038: val_loss did not improve from 0.07611\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0495 - accuracy: 0.9995 - val_loss: 0.0797 - val_accuracy: 0.9908 - lr: 0.0450\n",
            "Epoch 39/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9996\n",
            "Epoch 00039: val_loss did not improve from 0.07611\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0471 - accuracy: 0.9996 - val_loss: 0.0768 - val_accuracy: 0.9910 - lr: 0.0450\n",
            "Epoch 40/70\n",
            "437/437 [==============================] - 113s 258ms/step - loss: 0.0461 - accuracy: 0.9996 - val_loss: 0.0736 - val_accuracy: 0.9916 - lr: 0.0450\n",
            "Epoch 41/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9996\n",
            "Epoch 00041: val_loss did not improve from 0.07361\n",
            "437/437 [==============================] - 112s 255ms/step - loss: 0.0456 - accuracy: 0.9996 - val_loss: 0.0775 - val_accuracy: 0.9909 - lr: 0.0450\n",
            "Epoch 42/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9991\n",
            "Epoch 00042: val_loss did not improve from 0.07361\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0497 - accuracy: 0.9991 - val_loss: 0.0763 - val_accuracy: 0.9909 - lr: 0.0450\n",
            "Epoch 43/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9998\n",
            "Epoch 00043: val_loss did not improve from 0.07361\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0445 - accuracy: 0.9998 - val_loss: 0.0739 - val_accuracy: 0.9913 - lr: 0.0450\n",
            "Epoch 44/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9996\n",
            "Epoch 00044: val_loss improved from 0.07361 to 0.07302, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 113s 258ms/step - loss: 0.0440 - accuracy: 0.9996 - val_loss: 0.0730 - val_accuracy: 0.9913 - lr: 0.0450\n",
            "Epoch 45/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9996\n",
            "Epoch 00045: val_loss did not improve from 0.07302\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0451 - accuracy: 0.9996 - val_loss: 0.0821 - val_accuracy: 0.9892 - lr: 0.0450\n",
            "Epoch 46/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9993\n",
            "Epoch 00046: val_loss did not improve from 0.07302\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0477 - accuracy: 0.9993 - val_loss: 0.0788 - val_accuracy: 0.9895 - lr: 0.0450\n",
            "Epoch 47/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9987\n",
            "Epoch 00047: val_loss did not improve from 0.07302\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0509 - accuracy: 0.9987 - val_loss: 0.0811 - val_accuracy: 0.9907 - lr: 0.0450\n",
            "Epoch 48/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9996\n",
            "Epoch 00048: val_loss did not improve from 0.07302\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0429 - accuracy: 0.9996 - val_loss: 0.0742 - val_accuracy: 0.9917 - lr: 0.0450\n",
            "Epoch 49/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9997\n",
            "Epoch 00049: val_loss did not improve from 0.07302\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0428 - accuracy: 0.9997 - val_loss: 0.0791 - val_accuracy: 0.9894 - lr: 0.0450\n",
            "Epoch 50/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9998\n",
            "Epoch 00050: val_loss improved from 0.07302 to 0.07115, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.0415 - accuracy: 0.9998 - val_loss: 0.0711 - val_accuracy: 0.9913 - lr: 0.0450\n",
            "Epoch 51/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9991\n",
            "Epoch 00051: val_loss did not improve from 0.07115\n",
            "437/437 [==============================] - 112s 256ms/step - loss: 0.0458 - accuracy: 0.9991 - val_loss: 0.0763 - val_accuracy: 0.9904 - lr: 0.0450\n",
            "Epoch 52/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9993\n",
            "Epoch 00052: val_loss did not improve from 0.07115\n",
            "437/437 [==============================] - 112s 255ms/step - loss: 0.0461 - accuracy: 0.9993 - val_loss: 0.0808 - val_accuracy: 0.9893 - lr: 0.0450\n",
            "Epoch 53/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9996\n",
            "Epoch 00053: val_loss improved from 0.07115 to 0.06925, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.0418 - accuracy: 0.9996 - val_loss: 0.0693 - val_accuracy: 0.9923 - lr: 0.0450\n",
            "Epoch 54/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9997\n",
            "Epoch 00054: val_loss did not improve from 0.06925\n",
            "437/437 [==============================] - 112s 255ms/step - loss: 0.0417 - accuracy: 0.9997 - val_loss: 0.0724 - val_accuracy: 0.9913 - lr: 0.0450\n",
            "Epoch 55/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9996\n",
            "Epoch 00055: val_loss did not improve from 0.06925\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0419 - accuracy: 0.9996 - val_loss: 0.0716 - val_accuracy: 0.9909 - lr: 0.0450\n",
            "Epoch 56/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9997\n",
            "Epoch 00056: val_loss did not improve from 0.06925\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0405 - accuracy: 0.9997 - val_loss: 0.0882 - val_accuracy: 0.9889 - lr: 0.0450\n",
            "Epoch 57/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9989\n",
            "Epoch 00057: val_loss did not improve from 0.06925\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0524 - accuracy: 0.9989 - val_loss: 0.0754 - val_accuracy: 0.9903 - lr: 0.0450\n",
            "Epoch 58/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9992\n",
            "Epoch 00058: val_loss did not improve from 0.06925\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0461 - accuracy: 0.9992 - val_loss: 0.0748 - val_accuracy: 0.9902 - lr: 0.0450\n",
            "Epoch 59/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9996\n",
            "Epoch 00059: val_loss did not improve from 0.06925\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0409 - accuracy: 0.9996 - val_loss: 0.0739 - val_accuracy: 0.9905 - lr: 0.0450\n",
            "Epoch 60/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9997\n",
            "Epoch 00060: val_loss did not improve from 0.06925\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0413 - accuracy: 0.9997 - val_loss: 0.0724 - val_accuracy: 0.9908 - lr: 0.0450\n",
            "Epoch 61/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9992\n",
            "Epoch 00061: val_loss did not improve from 0.06925\n",
            "437/437 [==============================] - 111s 254ms/step - loss: 0.0438 - accuracy: 0.9992 - val_loss: 0.0872 - val_accuracy: 0.9877 - lr: 0.0450\n",
            "Epoch 62/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9994\n",
            "Epoch 00062: val_loss did not improve from 0.06925\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0412 - accuracy: 0.9994 - val_loss: 0.0753 - val_accuracy: 0.9902 - lr: 0.0450\n",
            "Epoch 63/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9997\n",
            "Epoch 00063: val_loss did not improve from 0.06925\n",
            "\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.02250000089406967.\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0400 - accuracy: 0.9997 - val_loss: 0.0707 - val_accuracy: 0.9910 - lr: 0.0450\n",
            "Epoch 64/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9999\n",
            "Epoch 00064: val_loss improved from 0.06925 to 0.06813, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.0377 - accuracy: 0.9999 - val_loss: 0.0681 - val_accuracy: 0.9913 - lr: 0.0225\n",
            "Epoch 65/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9998\n",
            "Epoch 00065: val_loss improved from 0.06813 to 0.06570, saving model to Densenet-BALANCED_DATA.h5\n",
            "437/437 [==============================] - 112s 257ms/step - loss: 0.0380 - accuracy: 0.9998 - val_loss: 0.0657 - val_accuracy: 0.9922 - lr: 0.0225\n",
            "Epoch 66/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9998\n",
            "Epoch 00066: val_loss did not improve from 0.06570\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0377 - accuracy: 0.9998 - val_loss: 0.0671 - val_accuracy: 0.9918 - lr: 0.0225\n",
            "Epoch 67/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9999\n",
            "Epoch 00067: val_loss did not improve from 0.06570\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0367 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9918 - lr: 0.0225\n",
            "Epoch 68/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 1.0000\n",
            "Epoch 00068: val_loss did not improve from 0.06570\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9918 - lr: 0.0225\n",
            "Epoch 69/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9999\n",
            "Epoch 00069: val_loss did not improve from 0.06570\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0358 - accuracy: 0.9999 - val_loss: 0.0680 - val_accuracy: 0.9915 - lr: 0.0225\n",
            "Epoch 70/70\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9999\n",
            "Epoch 00070: val_loss did not improve from 0.06570\n",
            "437/437 [==============================] - 111s 255ms/step - loss: 0.0364 - accuracy: 0.9999 - val_loss: 0.0665 - val_accuracy: 0.9923 - lr: 0.0225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF5o5XmYiUR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = load_model('Densenet-BALANCED_DATA.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WT3Fg4pEiHR",
        "colab_type": "code",
        "outputId": "d68c7b63-6106-4d7c-feb6-d77ae3a4b970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "score = best_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.06869985163211823\n",
            "Test accuracy: 0.9904577732086182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtwD6akJE35J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocess Test Images\n",
        "sharp_resized_array_TEST = []\n",
        "for i in range(len(test_images)):\n",
        "  img = test_images[i]\n",
        "  resized = cv2.resize(img, (128, 128))\n",
        "  sharp = unsharp_mask(resized)\n",
        "  sharp_resized_array_TEST.append(np.array(sharp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvWgn2u3MpD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sharp_resized_array_TEST_np = np.array(sharp_resized_array_TEST)\n",
        "sharp_resized_array_TEST_np.astype('float32')\n",
        "sharp_resized_array_TEST_np = preprocess_input(sharp_resized_array_TEST_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVH1WVZ8Mo8N",
        "colab_type": "code",
        "outputId": "88ed1683-5484-42c0-d506-3453c87ea9f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10838, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWkDY_Hci892",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_class = []\n",
        "for i in range(len(sharp_resized_array_TEST_np)):\n",
        "  img = sharp_resized_array_TEST_np[i]\n",
        "  img = np.expand_dims(img, axis = 0)\n",
        "  prediction = best_model.predict(img)\n",
        "  pred_class.append(np.argmax(prediction))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRgcGXAeHDyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb67xhGtmwl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame(pred_class)\n",
        "submission.to_csv('Densenet-BALANCED_DATA.csv', header=['class_index'],index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huokxkynneBH",
        "colab_type": "code",
        "outputId": "23b61755-9823-4d15-97e4-54c379982058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0\n",
              "0  37\n",
              "1  30\n",
              "2  34\n",
              "3  30\n",
              "4   6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V1USUV-R5q0",
        "colab_type": "text"
      },
      "source": [
        "#TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfifxBF5oBt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}